# 시계열

### 정상성(Stationary)

✓ 시간에 상관없이 일정한 성질이 나타남 (평균, 분산, 공분산 등) 

✓ 시계열에서 가장 이상적인 데이터의 상태 

✓ 데이터가 정상성일 때, 미래 데이터(Future Data) 예측 및 추론이 가능함 

✓ 그러나, 현실에서는 이러한 데이터는 찾기 어렵기 때문에, 데이터 변환 필수

=> 차분을 통해 데이터의 비정상성을 제거(데이터를 이상적인 형태로 변형)



### 비정상과정(NonStationary Process)

✓ 시간에 따라 평균과 분산이 달라지는 시계열 데이터 

✓ 이러한 시계열은 대부분 평균에서 벗어나서 불규칙하게 움직이며 시간에 따라 완만하게 움직이는 추세(trend)



### 정상 시계열 여부를 확인하는 방법 3가지

✓ 시계열 그래프(Time Series Plot) 

✓ 통계적 가설 검정 (Statistical Hypothesis Test) 

✓ 자기상관함수(ACF), 편자기상관함수(PACF)



> 자기상관함수, 편자기상관함수
> ✓ Take the log : 
> 
>    ▪ np.log(df) 
> 
> ✓ Take the quare root
> 
>    ▪ np.sqrt(df) 
> ✓ Take the proportional change





### 비정상시계열 데이터를 정상시계열 데이터로 변환

✓ ARIMA 시계열분석에서는 정상프로세스를 가진 시계열 데이터를 분석대상으로 가정 

✓ 비정상과정을 띠는 시계열 데이터는 차분(differencing)을 이용하여 정상시계열 데이터로 바꾼 다음 사용

✓ 𝑑 차 차분은 현시점 데이터 값에서 𝑑 시점 이전의 데이터 값을 빼서 계산함



---

# 순환 신경망

> 시계열 예측 모델에서 CNN 모델을 활용하지 않는 이유 : 최근 데이터가 5일 전 데이터보다 다음날 예측하는 데 훨씬 유용함



**순환 신경망의 등장**

- RNN (Recurrent Neural Network)

- LSTM (Long Short-Term Memory)

- 두 신경망은 인간의 기억을 모방(CNN은 인간의 시각적 이미지 인식을 모방)



**기본 개념**

- 문장을 읽을 때 이전에 나온 것을 기억하면서 단어별로 또는 한눈에 들어오는 만큼씩 처리

- 과거 정보를 사용하여 구축되며 새롭게 얻은 정보를 계속 업데이트



### RNN

- 루프(loop)를 가진 순환 신경망

<img src="file:///Users/angela/Library/Application%20Support/marktext/images/2023-08-30-10-27-47-image.png" title="" alt="" width="354">

- 시퀀스의 원소 순회하면서 지금까지 처리한 정보를 상태(state)에 저장

- RNN의 상태는 2개의 다른 시퀀스 처리하는 사이 재설정



![](/Users/angela/Library/Application%20Support/marktext/images/2023-08-30-10-30-44-image.png)





### LSTM

- RNN의 한계 : 그레이디언트 소실
  
  - RNN은 이론적으로 현재시간 t에서 이전의 모든 타임스텝의 정보 유지 가능
  
  - 긴 시간에 걸친 의존성은 학습할 수 없음

- LSTM은 정보를 여러 타임 스텝에 걸쳐 나르는 방법

- 핵심은 **과거 정보를 나중에 다시 주입하여 기울기 소실 문제 해결**한다는 것


